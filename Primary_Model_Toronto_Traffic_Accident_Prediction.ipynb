{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "This notebook processes Toronto road network and collision data to create a timeseries dataset for an accident prediction model for the Toronto downtown core. It also contains a traffic accident risk prediction model that is trained on this dataset for the Toronto downtown core.\n",
        "\n",
        "The dataset sources are:\n",
        "1. [NRN Ontario GeoPackage](https://open.canada.ca/data/en/dataset/3d282116-e556-400c-9306-ca1a3cada77f/resource/d07a84dd-863c-4d60-9c08-0b33b6120427)\n",
        "2. [Toronto neighbourhood spatial data](https://open.toronto.ca/dataset/neighbourhoods/)\n",
        "3. [Toronto collision dataset](https://open.toronto.ca/dataset/police-annual-statistical-report-traffic-collisions/)"
      ],
      "metadata": {
        "id": "mT18dx4hZiPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Notebook setup"
      ],
      "metadata": {
        "id": "veqIG9NpaTPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First installing useful modules:"
      ],
      "metadata": {
        "id": "ZeGaojNjb8lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas shapely torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKsfj4PiZgJU",
        "outputId": "70ec2836-7f59-4ef6-e1b6-833364d83778",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (25.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.8.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, importing necessary modules:"
      ],
      "metadata": {
        "id": "KgmNvprRdL1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import torch_geometric as pyg\n",
        "from torch_geometric.nn import GCNConv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "import shapely\n",
        "from shapely.geometry import Point"
      ],
      "metadata": {
        "id": "k-KkwWGxZ6Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Preprocessing GeoDataFrames"
      ],
      "metadata": {
        "id": "q1KR6epPkOoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1: Extracting raw data"
      ],
      "metadata": {
        "id": "gS4HwDhanvYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting google drive and changing working directory:"
      ],
      "metadata": {
        "id": "26vK7rbfgQ-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NHDViExUnuxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c36ecd2b-519a-4129-b889-69e53b10a774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: paste your own working directory here and then run the cell proceed with the next steps\n",
        "\n",
        "%cd \"/content/drive/MyDrive/2. UofT/2024-2025 (PEY)/Summer 2025/APS360 (2025)/APS360 2025 Project\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kymz-WtieDOi",
        "outputId": "05cead22-71ad-4bf8-f4bb-4f7742cf7285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/2. UofT/2024-2025 (PEY)/Summer 2025/APS360 (2025)/APS360 2025 Project'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading raw datasets and converting to GeoDataFrames"
      ],
      "metadata": {
        "id": "802WemHRgV4m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxnHDmXQm_N5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "aa83b7a4-b214-4819-8c7a-588f6cdb60da"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "DataSourceError",
          "evalue": "./3. Data and processing/DTC Road Network Data/NRN_RRN_ON_GPKG/NRN_ON_18_0_GPKG_en.gpkg: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-170680690.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Available layers: 'NRN_ON_18_0_TOLLPOINT' (default), 'NRN_ON_18_0_FERRYSEG', 'NRN_ON_18_0_JUNCTION',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 'NRN_ON_18_0_ROADSEG', 'NRN_ON_18_0_BLKPASSAGE', 'NRN_ON_18_0_STRPLANAME', 'NRN_ON_18_0_ADDRANGE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m roads_gpd = gpd.read_file(\"./3. Data and processing/DTC Road Network Data/NRN_RRN_ON_GPKG/NRN_ON_18_0_GPKG_en.gpkg\", \\\n\u001b[0m\u001b[1;32m      4\u001b[0m                           layer = 'NRN_ON_18_0_ROADSEG')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pyogrio\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         return _read_file_pyogrio(\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file_pyogrio\u001b[0;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"include_fields\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyogrio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyogrio/geopandas.py\u001b[0m in \u001b[0;36mread_dataframe\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# as numpy does not directly support timezones.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime_as_string\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     result = read_func(\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyogrio/raw.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdataset_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preprocess_options_key_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     return ogr_read(\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mget_vsi_path_or_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpyogrio/_io.pyx\u001b[0m in \u001b[0;36mpyogrio._io.ogr_read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpyogrio/_io.pyx\u001b[0m in \u001b[0;36mpyogrio._io.ogr_open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mDataSourceError\u001b[0m: ./3. Data and processing/DTC Road Network Data/NRN_RRN_ON_GPKG/NRN_ON_18_0_GPKG_en.gpkg: No such file or directory"
          ]
        }
      ],
      "source": [
        "# Available layers: 'NRN_ON_18_0_TOLLPOINT' (default), 'NRN_ON_18_0_FERRYSEG', 'NRN_ON_18_0_JUNCTION',\n",
        "# 'NRN_ON_18_0_ROADSEG', 'NRN_ON_18_0_BLKPASSAGE', 'NRN_ON_18_0_STRPLANAME', 'NRN_ON_18_0_ADDRANGE'\n",
        "roads_gpd = gpd.read_file(\"./3. Data and processing/DTC Road Network Data/NRN_RRN_ON_GPKG/NRN_ON_18_0_GPKG_en.gpkg\", \\\n",
        "                          layer = 'NRN_ON_18_0_ROADSEG')\n",
        "\n",
        "# Making neighbourhoods gpd:\n",
        "nbhds_gpd = gpd.read_file(\"./3. Data and processing/DTC Road Network Data/Neighbourhoods - 4326.gpkg\")\n",
        "\n",
        "# Making collisions gpd:\n",
        "collisions_gpd = gpd.read_file('./3. Data and processing/Toronto Collision Data/Traffic Collisions - 4326.gpkg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2: Clipping datasets to Toronto downtown core"
      ],
      "metadata": {
        "id": "FNzZx_G5Pu42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## creating downtown core polygon\n",
        "##################################################################\n",
        "\n",
        "# Making list of neighbourhoods in Toronto downtown core\n",
        "dtc_nbhds_list = ['Annex', 'University', 'Kensington-Chinatown', 'Wellington Place', 'Bay-Cloverhill', \\\n",
        "             'Yonge-Bay Corridor', 'Church-Wellesley', 'Downtown Yonge East', 'North St.James Town', \\\n",
        "             'Cabbagetown-South St.James Town', 'Moss Park', 'Regent Park', 'Harbourfront-CityPlace']\n",
        "\n",
        "# Filtering to downtown core neighhbourhoods\n",
        "dtc_nbhds_gpd = nbhds_gpd[nbhds_gpd['AREA_NAME'].isin(dtc_nbhds_list)]\n",
        "\n",
        "# Dissolving interior boundaries to create a single polygon\n",
        "dtc_nbhds_gpd = dtc_nbhds_gpd.dissolve()\n",
        "\n",
        "\n",
        "# Reprojecting all gpds to match NRN road network (just in case)\n",
        "dtc_nbhds_gpd = dtc_nbhds_gpd.to_crs(epsg=4617)\n",
        "colls_gpd = collisions_gpd.to_crs(epsg=4617)\n",
        "\n",
        "\n",
        "##################################################################\n",
        "## using polygon to clip the NRN road network\n",
        "##################################################################\n",
        "\n",
        "roads_gpd_clipped = gpd.clip(roads_gpd, dtc_nbhds_gpd['geometry'], keep_geom_type=True)\n",
        "colls_gpd_clipped = gpd.clip(colls_gpd, dtc_nbhds_gpd['geometry'], keep_geom_type=True)"
      ],
      "metadata": {
        "id": "pkXvo633MU28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3: Processing time data into [year, month, day, hour] format"
      ],
      "metadata": {
        "id": "ELAemSGVC9mU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this section is to have a consistent way of denoting the timepoint associated with each row in each GPD."
      ],
      "metadata": {
        "id": "m1w5N7uNIFCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## removing extraneous columns from GPDs\n",
        "##################################################################\n",
        "\n",
        "colls_gpd_clipped.drop(columns = [\"_id\", \"OCC_MONTH\", \"OCC_DOW\", \"OCC_YEAR\", \"DIVISION\", \"HOOD_158\", \"NEIGHBOURHOOD_158\", \"LONG_WGS84\", \"LAT_WGS84\", \"FATALITIES\"], \\\n",
        "                       inplace = True)"
      ],
      "metadata": {
        "id": "yDX6itJlEG_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## replacing time-related columns with columns of format [YEAR, MONTH, DAY, HOUR] for collisions\n",
        "##################################################################\n",
        "\n",
        "## For colls_gpd_clipped, we can use the datetime and zoneinfo modules to get the necessary date and hour info\n",
        "\n",
        "# Making custom get_coll_time_info() function that creates a pd Series of time information\n",
        "def get_coll_time_info(occ_date):\n",
        "\n",
        "  date_EST = datetime.fromtimestamp(int(occ_date) / 1000, ZoneInfo(\"America/Toronto\"))\n",
        "\n",
        "  return pd.Series([date_EST.year, date_EST.month, date_EST.day])\n",
        "\n",
        "\n",
        "# Making coll_OCC_convert() funciton to convert OCC_DATE data into\n",
        "def coll_OCC_convert(coll_df):\n",
        "\n",
        "  temp_df = pd.DataFrame()\n",
        "  temp_df[['YEAR', 'MONTH', 'DAY']] = coll_df[\"OCC_DATE\"].apply(get_coll_time_info)\n",
        "\n",
        "  coll_df.insert(coll_df.columns.get_loc('OCC_DATE'), 'YEAR', temp_df['YEAR'])\n",
        "  coll_df.insert(coll_df.columns.get_loc('OCC_DATE'), 'MONTH', temp_df['MONTH'])\n",
        "  coll_df.insert(coll_df.columns.get_loc('OCC_DATE'), 'DAY', temp_df['DAY'])\n",
        "  coll_df.pop(\"OCC_DATE\")\n",
        "\n",
        "\n",
        "# Applying functions to colls_gpd_clipped to modify it in place\n",
        "coll_OCC_convert(colls_gpd_clipped)\n",
        "\n",
        "# Renaming OCC_HOUR col to HOUR, in place, and turning str instries into int\n",
        "colls_gpd_clipped.rename(columns = {'OCC_HOUR': 'HOUR'}, inplace = True)      # Renames rows in place\n",
        "colls_gpd_clipped['HOUR'] = colls_gpd_clipped['HOUR'].apply(lambda x: int(x))\n",
        "\n",
        "\n",
        "# Removing duplicate entries and reindexing\n",
        "colls_gpd_clipped.drop_duplicates(subset = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'geometry'], keep = 'first', inplace = True)\n",
        "colls_gpd_clipped = colls_gpd_clipped.reset_index(drop = True)\n",
        "\n",
        "# Converting 'NO' and 'YES' entries into 0s and 1s\n",
        "colls_gpd_clipped.replace({'NO': 0, 'YES': 1, 'N/R': 0}, inplace = True)   # Modifies DF in place"
      ],
      "metadata": {
        "id": "xJ0poI75QF1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Creating Graphs, Timeseries, and Labels"
      ],
      "metadata": {
        "id": "_HwI2bz7N7Ps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1: Extracting nodes and edges from downtown core road network"
      ],
      "metadata": {
        "id": "4GfS1xiJVgoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Extracting endpoints (nodes) from the downtown core GPD\n",
        "##################################################################\n",
        "\n",
        "# Retrieving endpoints for each geometry\n",
        "endpts = roads_gpd_clipped['geometry'].boundary\n",
        "\n",
        "# Turning multipoints into single points, removing duplicates, and resetting index\n",
        "endpts = endpts.explode().drop_duplicates()   # endpts now represents our nodes\n",
        "\n",
        "# Convert the endpts GeoSeries to a GeoDataFrame\n",
        "endpts_gpd = gpd.GeoDataFrame(geometry = endpts)\n",
        "endpts_gpd = endpts_gpd.reset_index(drop = True)   # reorders endpts so that index starts from 0\n",
        "\n",
        "# Creating endpts dictionary to map a given coordinate (Point()) to a node number/order\n",
        "node_to_idx = {(pt[0]): ind for ind, pt in endpts_gpd.iterrows()}"
      ],
      "metadata": {
        "id": "wvz9EsbWVveV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Extracting edges and edge attributes from roads_gpd_clipped and node_to_idx\n",
        "##################################################################\n",
        "\n",
        "# Creating edge list using node_to_idx mapping\n",
        "edges = []\n",
        "edge_atts = []\n",
        "edge_weights = []\n",
        "\n",
        "for i, row in roads_gpd_clipped.explode().iterrows():\n",
        "\n",
        "  # Creating undirected edge list\n",
        "  start = Point(row['geometry'].coords[0])   # Wrapping in Point() since output is a tuple\n",
        "  end = Point(row['geometry'].coords[-1])    # Wrapping in Point() since output is a tuple\n",
        "\n",
        "  u_pos = node_to_idx[start]\n",
        "  v_pos = node_to_idx[end]\n",
        "\n",
        "  edges.append((u_pos, v_pos))\n",
        "  edges.append((v_pos, u_pos))\n",
        "\n",
        "  # Creating edge attribute matrix\n",
        "  edge_atts.append([row['PAVSTATUS'], row['ROADCLASS'], row['NBRLANES'], row['TRAFFICDIR'], row['geometry'].length])\n",
        "\n",
        "  # Creatng edge weight vector for compatibility with PyG GCN architecture\n",
        "  edge_weights.append(row['geometry'].length)\n",
        "\n",
        "\n",
        "# Duplicating the length values to match the number of directed edges\n",
        "edge_weights = edge_weights + edge_weights"
      ],
      "metadata": {
        "id": "RVSJ-7mC5SPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2: Snapping Collision Geometries to Nearest Nodes (Endpoints)"
      ],
      "metadata": {
        "id": "_EnRvmeHVnH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Creating feature_to_index mapping\n",
        "##################################################################\n",
        "\n",
        "# Note: this mapping is arbitrary\n",
        "coll_features = ['INJURY_COLLISIONS', 'FTR_COLLISIONS', 'PD_COLLISIONS', 'AUTOMOBILE',\t'MOTORCYCLE',\t'PASSENGER', 'BICYCLE', 'PEDESTRIAN']\n",
        "\n",
        "features = coll_features.copy()\n",
        "\n",
        "features_to_idx = {feats: i for i, feats in enumerate(features)}"
      ],
      "metadata": {
        "id": "37t2ohzZV1ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Preparing DFs by snapping geometries to node geometries\n",
        "##################################################################\n",
        "\n",
        "# Using shapely STRtree to build R-tree of endpoint geometries\n",
        "tree = shapely.STRtree(endpts)\n",
        "\n",
        "# Getting target indices of nearest points to speed_avg\n",
        "target_coll_idxs = tree.nearest(colls_gpd_clipped['geometry'])\n",
        "\n",
        "# Finding snapped speed geometries from target indices\n",
        "coll_snapped = tree.geometries.take(target_coll_idxs)\n",
        "\n",
        "# Converting to GeoDataFrame\n",
        "coll_snapped = gpd.GeoDataFrame(geometry = coll_snapped, crs = 'EPSG:4617')\n",
        "\n",
        "\n",
        "##################################################################\n",
        "## Replacing geometries in coll GPD with snapped geometries\n",
        "##################################################################\n",
        "\n",
        "# Updating coll GPD\n",
        "colls_gpd_clipped.pop(\"geometry\")\n",
        "colls_gpd_clipped['geometry'] = coll_snapped['geometry']"
      ],
      "metadata": {
        "id": "priW3YFFCaq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3: Creating Timeseries and Ground Truth Labels"
      ],
      "metadata": {
        "id": "BfWgI26rVwQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Creating list of GPDs where each entry is all collision events in a given hour\n",
        "##################################################################\n",
        "\n",
        "coll_grouped = colls_gpd_clipped.groupby(['YEAR', 'MONTH', 'DAY', 'HOUR'])   # Groups dataframe into hour-level spatial chunks\n",
        "\n",
        "ordered_coll_list = []\n",
        "\n",
        "for i in list(coll_grouped.groups):                      # Gets key from list of keys\n",
        "  ordered_coll_list.append(coll_grouped.get_group(i))    # Uses that key to access value (which are the gpd indices) and uses that as arg for .get_group()\n",
        "\n",
        "coll_timeseries = pd.concat(ordered_coll_list).reset_index(drop = True)\n",
        "\n",
        "\n",
        "##################################################################\n",
        "## Creating timepoint_to_index mapping\n",
        "##################################################################\n",
        "\n",
        "coll_timeseries_grouped = coll_timeseries.groupby(['YEAR', 'MONTH', 'DAY', 'HOUR'])\n",
        "timepoints_to_idx = {pt: idx for idx, pt in enumerate(coll_timeseries_grouped.groups.keys())}"
      ],
      "metadata": {
        "id": "dmwO5v22ZWUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Creating timeseries and labels array\n",
        "##################################################################\n",
        "\n",
        "timeseries = np.zeros(shape = (len(timepoints_to_idx), len(endpts), len(features)), dtype = np.float64)\n",
        "timeseries_labels = np.zeros(shape = (len(timepoints_to_idx), len(endpts), 1), dtype = np.float64)\n",
        "\n",
        "\n",
        "##################################################################\n",
        "## Populating timeseries with processed collision data and labels\n",
        "##################################################################\n",
        "\n",
        "# Iterating through coll_timeseries and updating timeseries and labels entries\n",
        "count = 0\n",
        "for i in coll_timeseries[['YEAR', 'MONTH', 'DAY', 'HOUR']].iterrows():\n",
        "\n",
        "  # Checking if timepoint tuple is in timepoints_to_idx mapping:\n",
        "  if tuple(i[1]) in timepoints_to_idx.keys():\n",
        "\n",
        "    # If the above is True, we update the features at the correct time and node index\n",
        "    timeseries[timepoints_to_idx[tuple(i[1])]][node_to_idx[coll_timeseries['geometry'].iloc[count]]][:] \\\n",
        "    = np.array(coll_timeseries.iloc[count][features], dtype = np.float64)\n",
        "\n",
        "    # If the above is True, we update the labels at the correct time and node index\n",
        "    timeseries_labels[timepoints_to_idx[tuple(i[1])]][node_to_idx[coll_timeseries['geometry'].iloc[count]]] = 1\n",
        "\n",
        "  count += 1"
      ],
      "metadata": {
        "id": "fkmFEZiJOcI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Preparing Input Data"
      ],
      "metadata": {
        "id": "J13YbkajXs9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1: Creating torch.tensors of Features and Labels"
      ],
      "metadata": {
        "id": "RQVb7V7zXwbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Creating [2, E] edge tensor\n",
        "##################################################################\n",
        "\n",
        "# Creating matrix of shape [2, E] for edges\n",
        "sources, targets = zip(*edges)\n",
        "edge_index_tensor = torch.tensor([sources, targets], dtype=torch.long)\n",
        "\n",
        "# Turning edge weights into torch tensor\n",
        "edge_weight_tensor = torch.tensor(edge_weights, dtype = torch.float)\n",
        "\n",
        "\n",
        "##################################################################\n",
        "## Creating features (input) and labels tensors\n",
        "##################################################################\n",
        "\n",
        "# turning node feature timeseries into torch tensor\n",
        "inputs = torch.tensor(timeseries, dtype = torch.float)\n",
        "\n",
        "# turning labels into torch tensor\n",
        "labels = torch.tensor(timeseries_labels, dtype = torch.float)"
      ],
      "metadata": {
        "id": "pr6Dh4boXscu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Creating sliding window of input tensors and associated ground truth labels\n",
        "##################################################################\n",
        "\n",
        "# Choosing window size of 7:\n",
        "window_size = 7\n",
        "\n",
        "# Choosing a window size of 7 to represent 'weeks' and permuting to have them in correct position\n",
        "input_w = inputs.unfold(dimension = 0, size = window_size, step = 1)\n",
        "input_w = torch.permute(input_w, (0, 3, 1, 2))\n",
        "\n",
        "# Removing last window (since there is no available ground truth)\n",
        "input_w = input_w[:-1]\n",
        "\n",
        "# Truncating labels to all occurrences at time t+1 relative to the end of each window\n",
        "labels_w = labels[window_size:]"
      ],
      "metadata": {
        "id": "frpwaUhUpFM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Reshaping the input and label windows to concatenate features across time\n",
        "##################################################################\n",
        "\n",
        "# Extracting dimensions\n",
        "w, t, n, f = input_w.shape\n",
        "\n",
        "# Permuting input_w\n",
        "input_w = torch.permute(input_w, (0, 2, 1, 3))\n",
        "input_w.shape\n",
        "\n",
        "# Reshaping to [w, n, t*f]\n",
        "input_w = torch.reshape(input_w, (w, n, t*f))"
      ],
      "metadata": {
        "id": "Sj8fyTRWK54A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2: Creating Training, Validation, and Test Sets"
      ],
      "metadata": {
        "id": "9YWTPIAdZFcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## loading all data into a PyG Data object\n",
        "##################################################################\n",
        "\n",
        "data_list = []\n",
        "\n",
        "for i in range(len(input_w)):\n",
        "  data_list.append(pyg.data.Data(x = input_w[i], edge_index = edge_index_tensor, edge_attr = edge_weight_tensor, y = labels[i]))"
      ],
      "metadata": {
        "id": "NqhZCbhDZJFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## loading all data into a PyG Data object\n",
        "##################################################################\n",
        "\n",
        "# Setting seed for reproducible shuffling\n",
        "torch.manual_seed(1000)\n",
        "\n",
        "split1 = int(0.7 * len(data_list))\n",
        "split2 = int(0.85 * len(data_list))\n",
        "\n",
        "train_data = data_list[:split1]\n",
        "val_data = data_list[split1:split2]\n",
        "test_data = data_list[split2:]\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "train_loader = pyg.loader.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "val_loader = pyg.loader.DataLoader(val_data, batch_size = batch_size, shuffle = False)\n",
        "test_loader = pyg.loader.DataLoader(test_data, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "00oDLDMdUw-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Building and Training ANN-GCN Model"
      ],
      "metadata": {
        "id": "6sIXAIUCa39m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1: Building ANN-GCN Model"
      ],
      "metadata": {
        "id": "-k2UyCPSa8cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Creating preliminary ANN-GCN hybrid\n",
        "##################################################################\n",
        "\n",
        "class ANN_GCN(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_linear, out_linear, hidden_channels, out_channels):\n",
        "    super(ANN_GCN, self).__init__()\n",
        "    self.name = 'ANN-GCN'\n",
        "\n",
        "    torch.manual_seed(10000)\n",
        "\n",
        "    self.linear1 = nn.Linear(in_channels, hidden_linear)\n",
        "    self.linear2 = nn.Linear(hidden_linear, out_linear)\n",
        "    self.conv1 = GCNConv(out_linear, hidden_channels)\n",
        "    self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "    self.linear3 = nn.Linear(out_channels, 1)\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index, edge_weight):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = F.relu(self.linear2(x))\n",
        "    x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
        "    x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
        "    x = self.linear3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "2QITxGO9a-bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2: Defining Training and Plotting Functions"
      ],
      "metadata": {
        "id": "Y5OohycfW_du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Creating training function\n",
        "##################################################################\n",
        "\n",
        "def train_net(net, train_loader, val_loader, learning_rate, epochs):\n",
        "\n",
        "    # Moving net to GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "      net = net.cuda()\n",
        "      pos_weight_tensor = torch.tensor(2000).cuda()  # Move pos_weight to GPU\n",
        "\n",
        "    # Using BCEWithLogitsLoss for binary classification\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight = pos_weight_tensor if torch.cuda.is_available() else torch.tensor(2000)) # Use the calculated pos_weight\n",
        "    optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
        "\n",
        "    # training the network and recording train and val accuracies\n",
        "    train_accuracy = np.zeros(epochs)\n",
        "    val_accuracy = np.zeros(epochs)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      num_correct = 0\n",
        "      total = 0\n",
        "\n",
        "      net.train() # Set the model to training mode\n",
        "\n",
        "      for i, batch in enumerate(train_loader):\n",
        "\n",
        "        node_feats = batch.x\n",
        "        edge_atts = batch.edge_attr\n",
        "        edge_index = batch.edge_index\n",
        "        labels = batch.y\n",
        "\n",
        "        # Reshaping labels to match output shape [batch_size * num_nodes, 1]\n",
        "        labels = labels.view(-1, 1)\n",
        "\n",
        "\n",
        "        # Moving tensors to the GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "          node_feats = node_feats.cuda()\n",
        "          edge_atts = edge_atts.cuda()\n",
        "          edge_index = edge_index.cuda()\n",
        "          labels = labels.cuda()\n",
        "\n",
        "        # doing forward and backward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(node_feats, edge_index, edge_atts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # computing the training accuracy\n",
        "        prediction = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        comparison = torch.eq(prediction, labels)\n",
        "        num_correct += int(torch.sum(comparison))\n",
        "        total += labels.size(0)   # Using the actual number of nodes in the batch\n",
        "\n",
        "\n",
        "      train_accuracy[epoch] = num_correct / total\n",
        "      val_accuracy[epoch] = accuracy(net, val_loader)\n",
        "\n",
        "      # Saving model checkpoint\n",
        "      model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
        "      torch.save(net.state_dict(), model_path)\n",
        "\n",
        "      # Printing results:\n",
        "      print(\"Epoch: {}, training accuracy: {}, validation accuracy: {}\".format(epoch + 1, train_accuracy[epoch], \\\n",
        "            val_accuracy[epoch]))\n",
        "\n",
        "    epochs = np.arange(1, epochs + 1)\n",
        "\n",
        "    return train_accuracy, val_accuracy, epochs\n",
        "\n",
        "\n",
        "##################################################################\n",
        "## Creating accuracy function\n",
        "##################################################################\n",
        "\n",
        "def accuracy(net, loader):\n",
        "    \"\"\"\n",
        "    This function evaluates a given model iteration on a dataset and returns the accuracy\n",
        "    for that dataset.\n",
        "    (nn.Module), (DataLoader) --> (int)\n",
        "    \"\"\"\n",
        "    net.eval() # Set the model to evaluation mode\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # evaluating the model on the given dataset and computing the accuracies\n",
        "    with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "        for i, batch in enumerate(loader):\n",
        "\n",
        "          node_feats = batch.x\n",
        "          edge_atts = batch.edge_attr\n",
        "          edge_index = batch.edge_index\n",
        "          labels = batch.y   # Removing unsqueeze(1)\n",
        "\n",
        "          # Reshaping labels to match output shape [batch_size * num_nodes, 1]\n",
        "          labels = labels.view(-1, 1)\n",
        "\n",
        "          # Moving tensors to the GPU if available\n",
        "          if torch.cuda.is_available():\n",
        "            node_feats = node_feats.cuda()\n",
        "            edge_atts = edge_atts.cuda()\n",
        "            edge_index = edge_index.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "          net_output = net(node_feats, edge_index, edge_atts)\n",
        "\n",
        "          # Computing the training accuracy\n",
        "          prediction = (torch.sigmoid(net_output) > 0.5).float()\n",
        "          comparison = torch.eq(prediction, labels)\n",
        "          num_correct += int(torch.sum(comparison))\n",
        "          total += labels.size(0)    # Using the actual number of nodes in the batch\n",
        "\n",
        "    return num_correct / total\n",
        "\n",
        "\n",
        "##################################################################\n",
        "## Creating get_model_name function\n",
        "##################################################################\n",
        "\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name, batch_size, learning_rate, epoch)\n",
        "    return path\n",
        "\n",
        "\n",
        "##################################################################\n",
        "## Creating plotting function\n",
        "##################################################################\n",
        "\n",
        "def plot_training_curve(training_accuracy, val_accuracy, epochs):\n",
        "    \"\"\" Plots the training curve for a model run, given training and\n",
        "    validation accuracy.\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.plot(epochs, training_accuracy, label = \"Training accuracy\")\n",
        "    plt.plot(epochs, val_accuracy, label = \"Validation accuracy\")\n",
        "    plt.xlabel(\"Epoch number\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YGzwcuARXfok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3: Training ANN-GCN Model"
      ],
      "metadata": {
        "id": "FacbXr6YXrww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Trianing model and plotting training curve\n",
        "##################################################################\n",
        "\n",
        "# Defining model\n",
        "model = ANN_GCN(56, 16, 8, 12, 1)\n",
        "\n",
        "# Training and plotting\n",
        "train_acc, val_acc, epochs = train_net(model, train_loader, val_loader, 0.0001, 10)\n",
        "plot_training_curve(train_acc, val_acc, epochs)"
      ],
      "metadata": {
        "id": "VFruU9e4XrQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Counting number of positive and negative samples in dataset\n",
        "##################################################################\n",
        "\n",
        "flat_labels = labels.view(-1)\n",
        "\n",
        "all_neg_acc = 1 - (torch.sum(flat_labels).item() / len(flat_labels))\n",
        "\n",
        "print(\"Approx. accuracy if all predictions were negative:\", all_neg_acc)"
      ],
      "metadata": {
        "id": "v3LeeQL0mrQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4: Evaluating Best Model on Test Set"
      ],
      "metadata": {
        "id": "ZoTPbSXbmRp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################\n",
        "## Loading best model\n",
        "##################################################################\n",
        "\n",
        "best_checkpoint_path = get_model_name(model.name, 20, 0.0001, 9)\n",
        "\n",
        "best_model = ANN_GCN(56, 16, 8, 12, 1)      # Making a new model to load best parameters into\n",
        "best_model.load_state_dict(torch.load(best_checkpoint_path))"
      ],
      "metadata": {
        "id": "f22LkxH7o-87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################\n",
        "# Evaluating model on the test set\n",
        "##############################\n",
        "\n",
        "# Moving best_model to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  best_model = best_model.cuda()\n",
        "\n",
        "test_acc = accuracy(best_model, test_loader)\n",
        "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))"
      ],
      "metadata": {
        "id": "_m8aeFsyqM4r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}